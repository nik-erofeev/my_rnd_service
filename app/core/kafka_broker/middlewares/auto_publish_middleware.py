import time
from collections.abc import Awaitable, Callable
from typing import Any

from faststream import BaseMiddleware, PublishCommand, StreamMessage

from app.core.config import CONFIG
from app.core.kafka_broker.schemas import HeadersTopikOut
from app.core.logger import get_logger
from app.core.logger.context_storage import message_headers, message_key, reset_request_context

logger = get_logger(__name__)


class AutoPublishMiddleware(BaseMiddleware):  # type: ignore[misc]
    """
    ÐÐ²Ñ‚Ð¾Ð¿ÑƒÐ±Ð»Ð¸ÐºÑƒÐµÑ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ñ…ÐµÐ½Ð´Ð»ÐµÑ€Ð° Ð² Ð²Ñ‹Ñ…Ð¾Ð´Ð½Ð¾Ð¹ Ñ‚Ð¾Ð¿Ð¸Ðº, ÐµÑÐ»Ð¸ Ð¾Ð½ Ð½Ðµ None.

    ÐÐ°Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ:
    - ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¿ÑƒÐ±Ð»Ð¸ÐºÑƒÐµÑ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ Ñ…ÐµÐ½Ð´Ð»ÐµÑ€Ð° Ð² Ð²Ñ‹Ñ…Ð¾Ð´Ð½Ð¾Ð¹ Ñ‚Ð¾Ð¿Ð¸Ðº (CONFIG.write_kafka.topic_out)
    - Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ key Ð¸Ð· contextvars (ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½ RequestContextMiddleware)
    - Headers Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¿Ð¾Ð´ÑÑ‚Ð°Ð²Ð»ÑÑŽÑ‚ÑÑ
    - Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÑ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¿ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ†Ð¸Ð¸ (ÑƒÑÐ¿ÐµÑ…/Ð¾ÑˆÐ¸Ð±ÐºÐ°/Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚)
    - Ð˜Ð·Ð¼ÐµÑ€ÑÐµÑ‚ Ð²Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ

    ÐŸÐ¾Ñ€ÑÐ´Ð¾Ðº Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ: ÐŸÐ¾ÑÐ»Ðµ RetryMiddleware, Ð¿ÐµÑ€ÐµÐ´ exc_middleware.
    ÐŸÐµÑ€ÐµÑ…Ð²Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ñ…ÐµÐ½Ð´Ð»ÐµÑ€Ð° Ð¸ Ð¿ÑƒÐ±Ð»Ð¸ÐºÑƒÐµÑ‚ ÐµÐ³Ð¾ Ð² Kafka.
    """

    async def consume_scope(
        self,
        call_next: Callable[[StreamMessage[Any]], Awaitable[Any]],
        msg: StreamMessage[Any],
    ) -> Any:
        started_at = time.perf_counter()
        result: Any | None = None
        publish_success = False
        publish_error: Exception | None = None
        processing_error: Exception | None = None

        try:
            result = await call_next(msg)

            if result is not None:
                try:
                    await self._publish_result(result)
                    publish_success = True
                except Exception as e:  # noqa: PERF203
                    publish_error = e
                    logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ†Ð¸Ð¸ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°: {e}", exc_info=True)

            return result
        except Exception as e:  # noqa: PERF203
            processing_error = e
            raise
        finally:
            elapsed = time.perf_counter() - started_at
            r = msg.raw_message
            partition = r.partition
            offset = r.offset

            if processing_error:
                logger.error(
                    f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸: {processing_error} | topic={CONFIG.write_kafka.topic_out} | partition={partition} | offset={offset} | Ð²Ñ€ÐµÐ¼Ñ:â±ï¸ {elapsed:.3f}Ñ",  # noqa: E501
                )
            elif result is None:
                logger.info(
                    f"â„¹ï¸ ÐŸÑƒÑÑ‚Ð¾Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ | topic={CONFIG.write_kafka.topic_out} | partition={partition} | offset={offset} | Ð²Ñ€ÐµÐ¼Ñ:â±ï¸ {elapsed:.3f}Ñ",  # noqa: E501
                )
            elif publish_success:
                logger.info(
                    f"âœ… Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¾Ð¿ÑƒÐ±Ð»Ð¸ÐºÐ¾Ð²Ð°Ð½ | topic={CONFIG.write_kafka.topic_out} | partition={partition} | offset={offset} | Ð²Ñ€ÐµÐ¼Ñ:â±ï¸ {elapsed:.3f}Ñ",  # noqa: E501
                )
            elif publish_error:
                logger.error(
                    f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ†Ð¸Ð¸: {publish_error} | topic={CONFIG.write_kafka.topic_out} | partition={partition} | offset={offset} | Ð²Ñ€ÐµÐ¼Ñ:â±ï¸ {elapsed:.3f}Ñ",  # noqa: E501
                )
            else:
                logger.warning(
                    f"âš ï¸ ÐÐµÐ¾Ð¶Ð¸Ð´Ð°Ð½Ð½Ð¾Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ AutoPublishMiddleware | topic={CONFIG.write_kafka.topic_out} | partition={partition} | offset={offset} | Ð²Ñ€ÐµÐ¼Ñ:â±ï¸ {elapsed:.3f}Ñ",  # noqa: E501
                )
            # Ð¿Ñ€Ð¸ ÑƒÑÐ¿ÐµÑ…Ðµ ÑÐ±Ñ€Ð°ÑÑ‹Ð²Ð°ÐµÐ¼, Ð¿Ñ€Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐµ ÑÐ±Ñ€Ð°ÑÑ‹Ð²Ð°ÐµÑ‚ÑÑ Ð² exc
            if not processing_error:
                reset_request_context()

    @staticmethod
    async def _publish_result(result: Any) -> None:
        from app.core.kafka_broker.brokers import broker

        message_data = result.model_dump(exclude_none=True) if hasattr(result, "model_dump") else result

        # Ð¼ÐµÐ½ÑÐµÐ¼ Ñ…ÐµÐ´ÐµÑ€Ñ‹ (ÐµÑÐ»Ð¸ Ð¼ÐµÐ½ÑÑŽÑ‚ÑÑ)
        current_headers = message_headers.get() or {}
        new_headers = HeadersTopikOut(
            requestId=str(current_headers.get("requestId")),
        ).model_dump(exclude_none=True)

        key = message_key.get()

        logger.info(
            f"ðŸ“¤ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð² Ñ‚Ð¾Ð¿Ð¸Ðº: {CONFIG.write_kafka.topic_out} | "
            f"message: {message_data} | headers: {new_headers} | key: {key!r}",
        )

        await broker.publish(
            message=message_data,
            topic=CONFIG.write_kafka.topic_out,
            headers=new_headers,
            key=key,
        )

    async def publish_scope(
        self,
        call_next: Callable[[PublishCommand], Awaitable[Any]],
        cmd: PublishCommand,
    ) -> Any:
        return await call_next(cmd)
