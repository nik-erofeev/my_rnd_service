services:
  kafka_template:
    #    image: bitnami/kafka:3.5.0
    image: docker.io/bitnamilegacy/kafka:3.5.0
    container_name: kafka_template
    hostname: kafka
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      # Включаем KRaft (без ZooKeeper)
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER

      # Три листенера: внутренний (PLAINTEXT), внешний (OUTSIDE), контроллер (CONTROLLER)
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,OUTSIDE://:29092,CONTROLLER://:9093

      # Протоколы
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,OUTSIDE:PLAINTEXT,CONTROLLER:PLAINTEXT

      # Рекламируемые адреса:
      # - Внутри Docker: kafka:9092
      # - С хоста: localhost:29092
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,OUTSIDE://localhost:29092

      # Указываем, что OUTSIDE слушает на localhost:29092
      - KAFKA_CFG_LISTENER_NAME_OUTSIDE_ADVERTISED_HOST_NAME=localhost
      - KAFKA_CFG_LISTENER_NAME_OUTSIDE_ADVERTISED_PORT=29092

      # Кворум контроллера
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093

      # ID брокера
      - KAFKA_BROKER_ID=1

      # Разрешить plaintext (для тестов)
      - ALLOW_PLAINTEXT_LISTENER=yes

    networks:
      #      - custom
      - default
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "bash", "-lc", "</dev/tcp/localhost/9092" ]
      interval: 10s
      timeout: 5s
      retries: 12

#  app_template_rag:
#    labels:
#      app_name: my_rnd_service
#    container_name: app-template-rag
#    build:
#      context: .
#      dockerfile: Dockerfile
#    restart: unless-stopped
#    # command: ['/app_example/docker/app.sh']
#    env_file:
#      - .env
#    depends_on:
#      - kafka_template
#    ports:
#      - "8080:8080"
#    networks:
##      - custom
#      - default
#    healthcheck:
##     test: ["CMD", "curl", "-f", "http://localhost:8080/health"]  # faststream
#     test: ["CMD", "curl", "-f", "http://localhost:8080/live"]  # fastapi
#     interval: 30s
#     timeout: 5s
#     retries: 3

  # --- POSTGRES ---
  # 1. Postgres
  langfuse-db:
    image: postgres:16
    container_name: langfuse-db
    restart: unless-stopped
    environment:
      POSTGRES_USER: langfuse
      POSTGRES_PASSWORD: langfuse_password
      POSTGRES_DB: langfuse
    volumes:
      - langfuse_db_data:/var/lib/postgresql/data
    networks:
      - default
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U langfuse"]
      interval: 3s
      timeout: 3s
      retries: 10

  # 2. ClickHouse (БЕЗ Zookeeper, порт 9000 открыт)
  clickhouse:
    container_name: langfuse-clickhouse
    image: clickhouse/clickhouse-server:24.3
    restart: unless-stopped
    ports:
      - "8123:8123"
      - "9000:9000"
    environment:
      CLICKHOUSE_DB: langfuse
      CLICKHOUSE_USER: default
      CLICKHOUSE_PASSWORD: clickhouse
    volumes:
      - clickhouse_data:/var/lib/clickhouse
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    healthcheck:
      test: [ "CMD", "clickhouse-client", "--query", "SELECT 1" ]
      interval: 5s
      timeout: 5s
      retries: 10
    networks:
      - default

  # 3. Redis (ОБЯЗАТЕЛЬНО для v3)
  redis:
    image: redis:7
    container_name: langfuse-redis
    restart: unless-stopped
    command: >
      --requirepass myredissecret
    ports:
      - "6379:6379"
    networks:
      - default
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "myredissecret", "ping"]
      interval: 3s
      timeout: 10s
      retries: 10

  # 4. Minio (ОБЯЗАТЕЛЬНО для v3 - эмуляция S3)
  minio:
    image: minio/minio
    container_name: langfuse-minio
    restart: unless-stopped
    entrypoint: sh
    # Создаем бакет 'langfuse' при старте
    command: -c 'mkdir -p /data/langfuse && minio server --address ":9000" --console-address ":9001" /data'
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: miniosecret
    ports:
      - "9090:9000"
      - "9091:9001"
    volumes:
      - minio_data:/data
    networks:
      - default
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 3s
      timeout: 10s
      retries: 5

  # 5. Langfuse Web
  langfuse-web:
    image: langfuse/langfuse:3
    container_name: langfuse-web
    restart: unless-stopped
    depends_on:
      langfuse-db:
        condition: service_healthy
      clickhouse:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_started
    ports:
      - "3001:3000"
    environment: &langfuse_env
      - NODE_ENV=production
      - DATABASE_URL=postgresql://langfuse:langfuse_password@langfuse-db:5432/langfuse
      - NEXTAUTH_SECRET=supersecret
      - NEXTAUTH_URL=http://localhost:3001
      - SALT=saltsalt
      - ENCRYPTION_KEY=0000000000000000000000000000000000000000000000000000000000000000
      - TELEMETRY_ENABLED=false
      - LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES=true

      # --- CLICKHOUSE (Фикс кластера) ---
      - CLICKHOUSE_URL=http://default:clickhouse@clickhouse:8123
      - CLICKHOUSE_MIGRATION_URL=clickhouse://default:clickhouse@clickhouse:9000/langfuse
      - CLICKHOUSE_USER=default
      - CLICKHOUSE_PASSWORD=clickhouse
      - CLICKHOUSE_DB=langfuse
      - CLICKHOUSE_CLUSTER_ENABLED=false  # <--- ВАЖНО

      # --- REDIS ---
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_AUTH=myredissecret

      # --- S3 / MINIO (Фикс ZodError) ---
      - LANGFUSE_S3_EVENT_UPLOAD_BUCKET=langfuse
      - LANGFUSE_S3_EVENT_UPLOAD_ENDPOINT=http://minio:9000
      - LANGFUSE_S3_EVENT_UPLOAD_ACCESS_KEY_ID=minio
      - LANGFUSE_S3_EVENT_UPLOAD_SECRET_ACCESS_KEY=miniosecret
      - LANGFUSE_S3_EVENT_UPLOAD_REGION=auto
      - LANGFUSE_S3_EVENT_UPLOAD_FORCE_PATH_STYLE=true

      # (Для экспортов и медиа тоже нужны переменные, даже если не используются)
      - LANGFUSE_S3_MEDIA_UPLOAD_BUCKET=langfuse
      - LANGFUSE_S3_MEDIA_UPLOAD_ENDPOINT=http://minio:9000
      - LANGFUSE_S3_MEDIA_UPLOAD_ACCESS_KEY_ID=minio
      - LANGFUSE_S3_MEDIA_UPLOAD_SECRET_ACCESS_KEY=miniosecret
      - LANGFUSE_S3_MEDIA_UPLOAD_REGION=auto
      - LANGFUSE_S3_MEDIA_UPLOAD_FORCE_PATH_STYLE=true

    networks:
      - default

  # 6. Langfuse Worker
  langfuse-worker:
    image: langfuse/langfuse-worker:3
    container_name: langfuse-worker
    restart: unless-stopped
    depends_on:
      langfuse-db:
        condition: service_healthy
      clickhouse:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_started
    environment: *langfuse_env
    networks:
      - default
#  grafana:
#    container_name: grafana_1
#    image: grafana/grafana:12.1.0
#    restart: unless-stopped
#    ports:
#      - "3000:3000"
#    environment:
#      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
#      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
#      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
#      - GF_ANALYTICS_REPORTING_ENABLED=false
#      - GF_ANALYTICS_CHECK_FOR_UPDATES=false
#      - GF_LOG_LEVEL=debug
#    volumes:
#      - grafana_data:/var/lib/grafana
#      - ./docker/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources:ro
#    depends_on:
#      - prometheus
#    networks:
#      - default
#
#  prometheus:
#    container_name: prometheus_1
#    image: prom/prometheus:v2.53.0
#    restart: unless-stopped
#    ports:
#      - "9090:9090"
#    command:
#      - --config.file=/etc/prometheus/prometheus.yml
#    volumes:
#      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
#    networks:
#      - default
#
#  # для логов grafana-dashboard
#  loki:
#    container_name: ${DOCKER_NAME}_loki
#    image: grafana/loki:2.8.2
#    restart: unless-stopped
#    ports:
#      - "3100:3100"
#    command: -config.file=/etc/loki/local-config.yaml
#    volumes:
#      - ./docker/loki-config.yaml:/etc/loki/local-config.yaml:ro
#    networks:
#      - default
#
#  # для loki
#  promtail:
#    container_name: ${DOCKER_NAME}_promtail
#    image: grafana/promtail:2.8.2
#    user: "0:0" # Запуск от root для доступа к логам
#    restart: unless-stopped
#    ports:
#      - "9080:9080"
#    volumes:
#      - /var/lib/docker/containers:/var/lib/docker/containers:ro
#      - /var/run/docker.sock:/var/run/docker.sock:ro
#      - ./docker/promtail/config.yaml:/etc/promtail/config.yaml:ro
#    command: -config.file=/etc/promtail/config.yaml
#    networks:
#      - default
#    depends_on:
#      - loki

networks:
#  custom: #(имя сети) project_name_custom
  default: #(имя сети) project_name_custom
    driver: bridge

volumes:
  grafana_data:
  opensearch_data:
  langfuse_db_data:
  clickhouse_data:
  minio_data:
